{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/2024/07/flood_prediction_notebook/flood_prediciton_code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /teamspace/studios/this_studio/2024/07/flood_prediction_notebook/flood_prediciton_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mlflow\n",
    "import gc\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Models Libs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn import svm as svm\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Metric\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Mlflow\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "DROP_COLUMNS = ['id']\n",
    "CV = 3\n",
    "RANDOM_STATE = 42\n",
    "ORIGINAL_COLS = ['id','MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors', 'FloodProbability']\n",
    "\n",
    "# FILTER_COLS = ['id','MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "#        'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality']\n",
    "\n",
    "# EXT_FEATURES = ['City_Features','TopographyDrainage_meanshift','Climate_Features','Climate_Features_mul','Climate_Features_meanshift','MonsoonIntensity_meanshift','TopographyDrainage_meanshift',\n",
    "# 'InadequatePlanning_1']\n",
    "# FEATURES = FILTER_COLS + EXT_FEATURES\n",
    "\n",
    "# GridSearchCV Params\n",
    "PARAMS_LINEAR_REGRESSION = {}\n",
    "\n",
    "PARAMS_XGB = {}\n",
    "\n",
    "PARAMS_RANDOM_FOREST_REGRESSION = {\n",
    "    'n_estimators':[100,200], \n",
    "    # 'criterion':['squared_error','absolute_error','friedman_mse','poisson']\n",
    "}\n",
    "\n",
    "PARAMS_LASSO = {\n",
    "    'alpha':[0.1,0.01], \n",
    "    'max_iter':[100,500]\n",
    "}\n",
    "\n",
    "PARAMS_RIDGE = {\n",
    "    'alpha':[0.1,0.01], \n",
    "    'max_iter':[100,500]\n",
    "}\n",
    "\n",
    "PARAMS_SVM = {\n",
    "    'C': [1, 10], \n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "PARAMS_DEFAULT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('../data/train.csv')\n",
    "raw_valid= pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data):\n",
    "    df = data.copy()\n",
    "    cols = ['MonsoonIntensity', 'TopographyDrainage', 'RiverManagement',\n",
    "       'Deforestation', 'Urbanization', 'ClimateChange', 'DamsQuality',\n",
    "       'Siltation', 'AgriculturalPractices', 'Encroachments',\n",
    "       'IneffectiveDisasterPreparedness', 'DrainageSystems',\n",
    "       'CoastalVulnerability', 'Landslides', 'Watersheds',\n",
    "       'DeterioratingInfrastructure', 'PopulationScore', 'WetlandLoss',\n",
    "       'InadequatePlanning', 'PoliticalFactors']\n",
    "    df['ClimateImpact'] = df.MonsoonIntensity+df.ClimateChange\n",
    "    df['AnthropogenicPressure'] = df.Deforestation+df.Urbanization+df.AgriculturalPractices+df.Encroachments\n",
    "    df['InfrastructureQuality'] = df.DamsQuality+df.DrainageSystems+df.DeterioratingInfrastructure\n",
    "    df['CoastalVulnerabilityTotal'] = df.CoastalVulnerability+df.Landslides\n",
    "    df['PreventiveMeasuresEfficiency'] = df.RiverManagement+df.IneffectiveDisasterPreparedness+df.InadequatePlanning\n",
    "    df['EcosystemImpact'] = df.WetlandLoss+df.Watersheds\n",
    "    df['SocioPoliticalContext'] = df.PopulationScore+df.PoliticalFactors\n",
    "    df['Land_Use_Pressure'] = df.Urbanization+df.Deforestation+df.AgriculturalPractices\n",
    "    df['Environmental_Degradation']=df.Deforestation+df.Siltation+df.WetlandLoss+df.Landslides\n",
    "    df['Infrastructure_Vulnerability'] = df.DeterioratingInfrastructure+df.InadequatePlanning\n",
    "    df['Community_Preparednessg']= df.IneffectiveDisasterPreparedness+df.PoliticalFactors\n",
    "    df['Population_Density_Vulnerable_Areas']= df.PopulationScore+df.CoastalVulnerability\n",
    "    df['Climate_Change_Impact']= df.ClimateChange+df.MonsoonIntensity\n",
    "    df['River_Health']= df.RiverManagement+df.DamsQuality\n",
    "    df['ClimateImpact'] = df.MonsoonIntensity+df.ClimateChange\n",
    "    df['AnthropogenicPressure'] = df.Deforestation+df.Urbanization+df.AgriculturalPractices+df.Encroachments\n",
    "    df['InfrastructureQuality'] = df.DamsQuality+df.DrainageSystems+df.DeterioratingInfrastructure\n",
    "    df['CoastalVulnerabilityTotal'] = df.CoastalVulnerability+df.Landslides\n",
    "    df['PreventiveMeasuresEfficiency'] = df.RiverManagement+df.IneffectiveDisasterPreparedness+df.InadequatePlanning\n",
    "    df['EcosystemImpact'] = df.WetlandLoss+df.Watersheds\n",
    "    df['SocioPoliticalContext'] = df.PopulationScore+df.PoliticalFactors\n",
    "    df['Land_Use_Pressure']=df.Urbanization+df.Deforestation+df.AgriculturalPractices\n",
    "    df['Environmental_Degradation']=df.Deforestation+df.Siltation+df.WetlandLoss+df.Landslides\n",
    "    df['Infrastructure_Vulnerability'] = df.DeterioratingInfrastructure+df.InadequatePlanning\n",
    "    df['Community_Preparednessg']= df.IneffectiveDisasterPreparedness+df.PoliticalFactors\n",
    "    df['Population_Density_Vulnerable_Areas']= df.PopulationScore+df.CoastalVulnerability\n",
    "    df['Climate_Change_Impact']= df.ClimateChange+df.MonsoonIntensity\n",
    "    df['River_Health']= df.RiverManagement+df.DamsQuality\n",
    "    df['sum']= df.sum(axis=1)\n",
    "    df['mean']= df.mean(axis=1)\n",
    "    df['std'] = df.std(axis=1)\n",
    "    df['max'] = df.max(axis=1)\n",
    "    df['min'] = df.min(axis=1)\n",
    "    df['var'] = df.var(axis=1)\n",
    "    df['skew'] = df.skew(axis=1)\n",
    "    df['kurt'] = df.kurt(axis=1)\n",
    "    df['meadian'] = df.median(axis=1)\n",
    "    df['quant_25'] = df.quantile(0.25,axis=1)\n",
    "    df['quant_75'] = df.quantile(0.75,axis=1)\n",
    "    df['sum>72'] = np.where(df['sum']>72,1,0)\n",
    "    df['sum>100'] = np.where(df['sum']>100,1,0)\n",
    "    df['sum>50'] = np.where(df['sum']>50,1,0)\n",
    "    df['range']= df['max']-df['min']\n",
    "    for col in cols:\n",
    "        df[f\"{col}_2\"]= df[col]**2\n",
    "        df[f\"{col}_3\"]= df[col]**3\n",
    "        df[f\"{col}_3\"]= df[col]**4\n",
    "    for col in cols:\n",
    "        if col not in ['id','FloodProbability']:\n",
    "            df[f\"mad_{col}\"] = df[col] - df[col].median()\n",
    "            df[f\"mean_{col}\"] = df[col] - df[col].mean()\n",
    "            df[f\"std_{col}\"] = df[col] - df[col].std()\n",
    "    return df\n",
    "\n",
    "def process_data(train_data):\n",
    "    df = train_data.copy()\n",
    "    df = create_features(df)\n",
    "    # Drop Columns\n",
    "    df.drop(columns=DROP_COLUMNS,axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def evaluate_model(model_name):\n",
    "    # Linear Regression Model\n",
    "    if model_name=='linear_regression':\n",
    "        model =  GridSearchCV(\n",
    "            estimator=LinearRegression(),\n",
    "            param_grid=PARAMS_LINEAR_REGRESSION,\n",
    "            cv=CV,\n",
    "            n_jobs=-1,\n",
    "            verbose=2,\n",
    "            scoring='neg_mean_squared_error')\n",
    "        # Train Model\n",
    "        model.fit(X_train,y_train)\n",
    "        # Predict on Test\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Score \n",
    "        score = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # LASSO\n",
    "    if model_name=='lasso':\n",
    "        model =  GridSearchCV(\n",
    "            estimator=Lasso(),\n",
    "            param_grid=PARAMS_LASSO,\n",
    "            cv=CV,\n",
    "            n_jobs=-1,\n",
    "            verbose=2,\n",
    "            scoring='neg_mean_squared_error')\n",
    "        # Train Model\n",
    "        model.fit(X_train,y_train)\n",
    "        # Predict on Test\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Score \n",
    "        score = r2_score(y_test, y_pred)\n",
    "\n",
    "    # SVM Model\n",
    "    if model_name=='svm':\n",
    "        model =  GridSearchCV(\n",
    "            estimator=svm.SVR(),\n",
    "            param_grid=PARAMS_SVM,\n",
    "            cv=CV,\n",
    "            n_jobs=-1,\n",
    "            verbose=2,\n",
    "            scoring='neg_mean_squared_error')\n",
    "        # Train Model\n",
    "        model.fit(X_train,y_train)\n",
    "        # Predict on Test\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Score \n",
    "        score = r2_score(y_test, y_pred)\n",
    "        print(f'Finished training model {model_name}')\n",
    "\n",
    "    # XGBoost\n",
    "    if model_name=='xgb':\n",
    "        model =  GridSearchCV(\n",
    "            estimator=xgb.XGBRegressor(),\n",
    "            param_grid=PARAMS_XGB,\n",
    "            cv=CV,\n",
    "            n_jobs=-1,\n",
    "            verbose=2,\n",
    "            scoring='neg_mean_squared_error')\n",
    "        # Train Model\n",
    "        model.fit(X_train,y_train)\n",
    "        # Predict on Test\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Score \n",
    "        score = r2_score(y_test, y_pred)\n",
    "        print(f'Finished training model {model_name}')\n",
    "\n",
    "    # LightGBM\n",
    "    if model_name=='lgbm':\n",
    "        model =  GridSearchCV(\n",
    "            estimator=LGBMRegressor(),\n",
    "            param_grid=PARAMS_DEFAULT,\n",
    "            cv=CV,\n",
    "            n_jobs=-1,\n",
    "            verbose=2,\n",
    "            scoring='neg_mean_squared_error')\n",
    "        # Train Model\n",
    "        model.fit(X_train,y_train)\n",
    "        # Predict on Test\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Score \n",
    "        score = r2_score(y_test, y_pred)\n",
    "        print(f'Finished training model {model_name}')\n",
    "\n",
    "    # CatBoost\n",
    "    if model_name=='catboost':\n",
    "        model =  GridSearchCV(\n",
    "            estimator=CatBoostRegressor(),\n",
    "            param_grid=PARAMS_DEFAULT,\n",
    "            cv=CV,\n",
    "            n_jobs=-1,\n",
    "            verbose=2,\n",
    "            scoring='neg_mean_squared_error')\n",
    "        # Train Model\n",
    "        model.fit(X_train,y_train)\n",
    "        # Predict on Test\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Score \n",
    "        score = r2_score(y_test, y_pred)\n",
    "        print(f'Finished training model {model_name}')\n",
    "    \n",
    "    # \n",
    "    # Return\n",
    "    return model_name,score,model.best_estimator_,model.best_params_\n",
    "\n",
    "def run_experiment(model_name,exp_name):\n",
    "    mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "    mlflow.set_experiment(exp_name)\n",
    "    with mlflow.start_run():\n",
    "        print('Model Name : ',model_name)\n",
    "        model_name,score,best_model,best_param = evaluate_model(model_name)\n",
    "        mlflow.log_param('Drop Columns', DROP_COLUMNS)\n",
    "        mlflow.log_param('Model Name',model_name)\n",
    "        mlflow.log_params(best_param)\n",
    "        mlflow.log_param('CV',CV)\n",
    "        mlflow.log_param('Random State',RANDOM_STATE)\n",
    "        mlflow.log_param('Features', str(list(valid_X_scaled.columns)))\n",
    "        mlflow.log_metric('R2',score)\n",
    "        mlflow.sklearn.log_model(best_model,model_name)\n",
    "        # mlflow.log_artifact('transformed_data.csv')\n",
    "    return best_model\n",
    "\n",
    "def get_submission_csv(model):\n",
    "    predictions = model.predict(valid_X_scaled)\n",
    "    sub_df = raw_valid[['id']]\n",
    "    sub_df['FloodProbability'] = predictions\n",
    "    sub_df.to_csv('../data/submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split and Scaling\n",
    "raw_train_X = raw_train.drop('FloodProbability',axis=1)\n",
    "raw_train_y = raw_train['FloodProbability']\n",
    "\n",
    "train_X = process_data(raw_train_X)\n",
    "train_y = raw_train_y\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "sc.fit(train_X)\n",
    "train_X_scaled = sc.transform(train_X)\n",
    "train_X_scaled = pd.DataFrame(train_X,columns=train_X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X_scaled, train_y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "valid_X = process_data(raw_valid)\n",
    "valid_X_scaled = sc.transform(valid_X)\n",
    "valid_X_scaled = pd.DataFrame(valid_X_scaled,columns=valid_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1117957, 149), (745305, 149))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_scaled.shape, valid_X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del raw_train_X,raw_train_y,train_X,train_y,train_X_scaled\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name :  xgb\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=  47.8s\n",
      "[CV] END .................................................... total time=  49.5s\n",
      "[CV] END .................................................... total time=  52.5s\n",
      "Finished training model xgb\n"
     ]
    }
   ],
   "source": [
    "# md_lr = run_experiment('linear_regression','Without HP Tuning')\n",
    "# md_svm = run_experiment('svm','Without HP Tuning')\n",
    "# md_lgbm =run_experiment('lgbm','Without HP Tuning')\n",
    "md_xgb = run_experiment('xgb','Without HP Tuning')\n",
    "# md_catboost =run_experiment('catboost','Without HP Tuning')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
